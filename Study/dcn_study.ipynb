{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class DeformableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=False):\n",
    "        super(DeformableConv2d, self).__init__()\n",
    "\n",
    "        self.padding = padding\n",
    "\n",
    "        self.offset_conv = nn.Conv2d(in_channels,\n",
    "                                     2 * kernel_size * kernel_size,\n",
    "                                     kernel_size=kernel_size,\n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding,\n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
    "\n",
    "        self.modulator_conv = nn.Conv2d(in_channels,\n",
    "                                        1 * kernel_size * kernel_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride,\n",
    "                                        padding=self.padding,\n",
    "                                        bias=True)\n",
    "\n",
    "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
    "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
    "\n",
    "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=self.padding,\n",
    "                                      bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[2:]\n",
    "        max_offset = max(h, w) / 4.\n",
    "\n",
    "        offset = self.offset_conv(x).clamp(-max_offset, max_offset)\n",
    "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
    "\n",
    "        x = torchvision.ops.deform_conv2d(input=x,\n",
    "                                          offset=offset,\n",
    "                                          weight=self.regular_conv.weight,\n",
    "                                          bias=self.regular_conv.bias,\n",
    "                                          padding=self.padding,\n",
    "                                          mask=modulator\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([[[[0.6637, 0.9092, 0.0223,  ..., 0.1978, 0.6091, 0.1626],\n",
      "          [0.6127, 0.6896, 0.6134,  ..., 0.4563, 0.0801, 0.0066],\n",
      "          [0.0064, 0.8163, 0.5050,  ..., 0.9591, 0.7924, 0.8178],\n",
      "          ...,\n",
      "          [0.3406, 0.5611, 0.5172,  ..., 0.8362, 0.1288, 0.1834],\n",
      "          [0.6166, 0.6991, 0.3054,  ..., 0.5943, 0.4763, 0.2973],\n",
      "          [0.0375, 0.5085, 0.3162,  ..., 0.1681, 0.4985, 0.3899]],\n",
      "\n",
      "         [[0.4493, 0.1283, 0.0991,  ..., 0.9186, 0.8901, 0.3539],\n",
      "          [0.7714, 0.7382, 0.6651,  ..., 0.6157, 0.7067, 0.1467],\n",
      "          [0.3317, 0.1995, 0.2478,  ..., 0.7689, 0.7709, 0.8859],\n",
      "          ...,\n",
      "          [0.1119, 0.5473, 0.4853,  ..., 0.4273, 0.4752, 0.7518],\n",
      "          [0.5964, 0.4107, 0.2402,  ..., 0.7750, 0.4884, 0.2953],\n",
      "          [0.5156, 0.5605, 0.7330,  ..., 0.6830, 0.1961, 0.6793]],\n",
      "\n",
      "         [[0.8006, 0.1372, 0.0043,  ..., 0.5283, 0.9285, 0.3222],\n",
      "          [0.3775, 0.4026, 0.3167,  ..., 0.5116, 0.7442, 0.6276],\n",
      "          [0.8111, 0.8526, 0.4434,  ..., 0.7982, 0.0923, 0.9782],\n",
      "          ...,\n",
      "          [0.6422, 0.0392, 0.1342,  ..., 0.5199, 0.7492, 0.5777],\n",
      "          [0.3216, 0.6046, 0.1840,  ..., 0.2858, 0.2204, 0.7659],\n",
      "          [0.3183, 0.0504, 0.7057,  ..., 0.5301, 0.4048, 0.4605]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,3,224,224)\n",
    "print(x.shape)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n"
     ]
    }
   ],
   "source": [
    "h, w = x.shape[2:]\n",
    "print(h,w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.0\n"
     ]
    }
   ],
   "source": [
    "max_offset = max(h, w) / 4.\n",
    "print(max_offset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 224, 224])\n",
      "tensor([[[[-1.7576e-02,  3.4286e-02,  2.6968e-01,  ...,  5.6142e-04,\n",
      "           -3.9582e-01, -2.2050e-01],\n",
      "          [ 2.4251e-03, -4.4305e-02,  4.7127e-01,  ...,  3.0009e-01,\n",
      "            1.3429e-01, -1.1702e-01],\n",
      "          [ 1.5913e-01, -1.1701e-01,  2.3523e-01,  ...,  1.7050e-01,\n",
      "            2.6533e-01, -2.5244e-01],\n",
      "          ...,\n",
      "          [ 9.9858e-02,  2.7623e-01,  3.4265e-01,  ...,  1.5353e-01,\n",
      "            1.4916e-01, -1.0651e-01],\n",
      "          [ 1.3632e-01, -1.0728e-01,  2.3423e-02,  ...,  9.1937e-02,\n",
      "            3.8159e-01, -1.2229e-01],\n",
      "          [-1.6383e-02,  8.8191e-02,  5.5780e-02,  ...,  7.8856e-02,\n",
      "            3.4026e-02,  4.8762e-02]],\n",
      "\n",
      "         [[-3.4662e-01, -6.1628e-01, -5.8592e-01,  ..., -8.9743e-01,\n",
      "           -8.1005e-01, -4.5383e-01],\n",
      "          [-4.1726e-01, -5.3475e-01, -8.7211e-01,  ..., -8.2527e-01,\n",
      "           -7.2876e-01, -2.1188e-01],\n",
      "          [-4.2770e-01, -4.2792e-01, -6.7187e-01,  ..., -5.3343e-01,\n",
      "           -9.3921e-01, -5.0825e-01],\n",
      "          ...,\n",
      "          [-1.9816e-01, -3.3651e-01, -3.0002e-01,  ..., -8.6596e-01,\n",
      "           -4.8781e-01, -1.9241e-01],\n",
      "          [-2.6085e-01, -5.9975e-01, -5.9766e-01,  ..., -6.0507e-01,\n",
      "           -4.7281e-01, -3.4514e-01],\n",
      "          [-1.1337e-01, -3.1396e-01, -3.2203e-01,  ..., -4.6366e-01,\n",
      "           -3.9946e-01, -2.3529e-01]],\n",
      "\n",
      "         [[ 2.8960e-01, -5.0905e-02, -1.4027e-01,  ..., -6.9047e-02,\n",
      "            1.2934e-02, -1.5742e-01],\n",
      "          [ 2.4711e-01, -3.3717e-01, -2.2533e-01,  ..., -3.8204e-01,\n",
      "           -2.7731e-01, -5.4170e-01],\n",
      "          [ 2.6685e-01, -2.0935e-01, -4.7828e-01,  ..., -4.7061e-01,\n",
      "           -4.9644e-01, -1.7260e-01],\n",
      "          ...,\n",
      "          [ 1.2945e-01, -2.8308e-01, -2.4033e-01,  ..., -3.1269e-01,\n",
      "           -5.8630e-01, -4.0242e-01],\n",
      "          [ 1.7433e-01, -6.8554e-02, -1.6072e-01,  ..., -5.5375e-01,\n",
      "           -4.4318e-01, -1.4770e-01],\n",
      "          [ 6.6062e-02, -2.6653e-01, -1.7871e-01,  ..., -1.3182e-01,\n",
      "           -3.8253e-01, -9.7760e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4282e-02, -1.4662e-02, -1.7105e-01,  ..., -3.9300e-02,\n",
      "            1.4467e-01, -1.6898e-02],\n",
      "          [ 1.2244e-01,  3.3623e-02, -1.1601e-01,  ..., -3.5115e-01,\n",
      "           -1.1184e-01,  1.5619e-01],\n",
      "          [-1.3857e-01, -1.4697e-02, -9.4105e-02,  ...,  1.1098e-02,\n",
      "           -3.3374e-02,  4.7164e-01],\n",
      "          ...,\n",
      "          [-6.7692e-02, -6.4974e-02,  1.2362e-01,  ...,  2.2162e-01,\n",
      "            3.4235e-02,  4.4580e-01],\n",
      "          [ 1.1431e-01,  1.9922e-01,  1.3428e-01,  ...,  1.6221e-01,\n",
      "           -1.1174e-01,  3.5192e-01],\n",
      "          [ 2.0999e-01,  1.1548e-01,  3.6823e-01,  ...,  2.7944e-01,\n",
      "           -2.3483e-02,  3.2929e-01]],\n",
      "\n",
      "         [[ 4.9160e-02, -2.9016e-01, -2.6995e-01,  ..., -1.8813e-01,\n",
      "           -2.3725e-01, -1.4966e-01],\n",
      "          [-3.1366e-01, -3.0536e-01, -1.2116e-01,  ..., -1.0601e-01,\n",
      "           -2.8214e-01, -1.7168e-01],\n",
      "          [ 1.4194e-01, -1.6192e-01, -8.1493e-02,  ..., -1.1757e-01,\n",
      "           -2.1837e-01, -3.5924e-01],\n",
      "          ...,\n",
      "          [-1.2032e-01, -1.5018e-01, -2.9023e-01,  ..., -2.9211e-01,\n",
      "           -1.9667e-01, -3.3074e-01],\n",
      "          [-1.1912e-01, -1.9183e-01, -3.1015e-01,  ..., -3.5904e-01,\n",
      "           -9.1730e-02, -3.1909e-01],\n",
      "          [-1.4382e-01, -2.4632e-01,  8.7249e-03,  ..., -1.2166e-01,\n",
      "           -3.4315e-02, -2.4809e-01]],\n",
      "\n",
      "         [[ 7.8424e-02, -9.8371e-02, -4.3786e-02,  ...,  7.4762e-02,\n",
      "            5.4974e-02, -1.1119e-01],\n",
      "          [-2.6469e-01, -2.2784e-01,  2.0835e-01,  ...,  2.2651e-01,\n",
      "            2.1654e-01,  2.2140e-01],\n",
      "          [ 1.2064e-01, -4.6557e-03,  1.2034e-01,  ...,  2.1561e-01,\n",
      "            3.9291e-02,  3.1149e-01],\n",
      "          ...,\n",
      "          [-1.7691e-02,  2.2763e-02,  2.5850e-02,  ...,  3.7114e-02,\n",
      "            1.6253e-01,  5.3920e-02],\n",
      "          [ 1.3415e-01, -1.1272e-01, -1.6902e-01,  ...,  1.6060e-01,\n",
      "            1.4181e-01,  1.7783e-01],\n",
      "          [-7.1425e-02, -1.4167e-01,  2.4411e-01,  ..., -3.2619e-02,\n",
      "           -8.5068e-02,  5.0112e-03]]]], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "in_channels=3\n",
    "out_channels=3\n",
    "kernel_size=3\n",
    "stride=1\n",
    "padding=1\n",
    "bias=False\n",
    "\n",
    "offset_conv = nn.Conv2d(in_channels,out_channels=2 * kernel_size * kernel_size,kernel_size=kernel_size,stride=stride,padding=padding,bias=True)\n",
    "\n",
    "offset = offset_conv(x)\n",
    "offset = offset.clamp(-max_offset, max_offset)\n",
    "print(offset.shape)\n",
    "print(offset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "modulator_conv = nn.Conv2d(in_channels,\n",
    "                                        out_channels=1 * kernel_size * kernel_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride,\n",
    "                                        padding=padding,\n",
    "                                        bias=True)\n",
    "modulator = 2. * torch.sigmoid(modulator_conv(x))\n",
    "print(modulator.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([[[[ 0.0020,  0.0129,  0.0209,  ..., -0.0469, -0.0309,  0.0324],\n",
      "          [ 0.0091,  0.0049,  0.0068,  ..., -0.0462, -0.0217,  0.0256],\n",
      "          [ 0.0211,  0.0278, -0.0075,  ..., -0.0520, -0.0376,  0.0213],\n",
      "          ...,\n",
      "          [-0.0032, -0.0152, -0.0401,  ..., -0.0536, -0.0333, -0.0121],\n",
      "          [ 0.0296, -0.0050, -0.0164,  ..., -0.0568, -0.0620, -0.0634],\n",
      "          [-0.0083, -0.0204, -0.0537,  ..., -0.1018, -0.0949, -0.0885]],\n",
      "\n",
      "         [[-0.0335, -0.0154, -0.0455,  ..., -0.0135,  0.0054, -0.0253],\n",
      "          [-0.0770, -0.0726, -0.0355,  ..., -0.0852, -0.0790, -0.0297],\n",
      "          [-0.1309, -0.0898, -0.1053,  ..., -0.1011, -0.1116, -0.0053],\n",
      "          ...,\n",
      "          [-0.0845, -0.1279, -0.1345,  ..., -0.1476, -0.1351,  0.0063],\n",
      "          [-0.0652, -0.0859, -0.0831,  ..., -0.1181, -0.1347, -0.0074],\n",
      "          [-0.0432, -0.0426, -0.0542,  ..., -0.0916, -0.1086, -0.0304]],\n",
      "\n",
      "         [[ 0.0176,  0.0344,  0.0258,  ..., -0.0337,  0.0126,  0.0132],\n",
      "          [ 0.0375, -0.0062, -0.0489,  ..., -0.0418,  0.0164,  0.0284],\n",
      "          [ 0.0132, -0.0335, -0.0270,  ..., -0.0857, -0.0404,  0.0289],\n",
      "          ...,\n",
      "          [-0.0074, -0.0342, -0.0392,  ..., -0.0801, -0.0848, -0.0531],\n",
      "          [ 0.0162,  0.0003, -0.0437,  ..., -0.1059, -0.0908, -0.0382],\n",
      "          [-0.0051, -0.0137, -0.0010,  ..., -0.0214, -0.0210,  0.0224]]]],\n",
      "       grad_fn=<DeformConv2dFunction>>)\n"
     ]
    }
   ],
   "source": [
    "regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=padding,\n",
    "                                      bias=bias)\n",
    "\n",
    "x = torchvision.ops.deform_conv2d(input=x,offset=offset,weight=regular_conv.weight,bias=regular_conv.bias,padding=padding,mask=modulator)\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0569, 0.7440, 0.0140],\n",
      "          [0.0148, 0.6590, 0.4926],\n",
      "          [0.0950, 0.8827, 0.6277]],\n",
      "\n",
      "         [[0.4516, 0.7992, 0.5346],\n",
      "          [0.8951, 0.3522, 0.6384],\n",
      "          [0.1848, 0.9502, 0.1848]],\n",
      "\n",
      "         [[0.2099, 0.1302, 0.6574],\n",
      "          [0.1031, 0.8875, 0.5087],\n",
      "          [0.5917, 0.9960, 0.9076]]],\n",
      "\n",
      "\n",
      "        [[[0.8687, 0.6939, 0.4749],\n",
      "          [0.7885, 0.3227, 0.4976],\n",
      "          [0.9828, 0.9661, 0.3260]],\n",
      "\n",
      "         [[0.0874, 0.5775, 0.1695],\n",
      "          [0.5461, 0.6191, 0.0130],\n",
      "          [0.7924, 0.8268, 0.5407]],\n",
      "\n",
      "         [[0.5587, 0.9888, 0.0940],\n",
      "          [0.6395, 0.1014, 0.9123],\n",
      "          [0.8542, 0.1739, 0.9641]]],\n",
      "\n",
      "\n",
      "        [[[0.6092, 0.5315, 0.5009],\n",
      "          [0.0752, 0.9386, 0.0849],\n",
      "          [0.5047, 0.5962, 0.7937]],\n",
      "\n",
      "         [[0.0541, 0.0705, 0.9983],\n",
      "          [0.2636, 0.4181, 0.3774],\n",
      "          [0.2157, 0.8887, 0.9758]],\n",
      "\n",
      "         [[0.9315, 0.0792, 0.2303],\n",
      "          [0.1017, 0.6964, 0.3520],\n",
      "          [0.7284, 0.5469, 0.0180]]],\n",
      "\n",
      "\n",
      "        [[[0.6860, 0.9382, 0.2807],\n",
      "          [0.5192, 0.0501, 0.6083],\n",
      "          [0.2559, 0.7351, 0.9016]],\n",
      "\n",
      "         [[0.7189, 0.5766, 0.5010],\n",
      "          [0.3561, 0.6702, 0.1229],\n",
      "          [0.9016, 0.2327, 0.2251]],\n",
      "\n",
      "         [[0.5808, 0.7135, 0.3619],\n",
      "          [0.0270, 0.5586, 0.3247],\n",
      "          [0.2994, 0.5011, 0.2502]]],\n",
      "\n",
      "\n",
      "        [[[0.6288, 0.3499, 0.2175],\n",
      "          [0.2337, 0.0229, 0.7352],\n",
      "          [0.6536, 0.0013, 0.6612]],\n",
      "\n",
      "         [[0.0522, 0.1368, 0.0010],\n",
      "          [0.5735, 0.8573, 0.2067],\n",
      "          [0.8884, 0.2052, 0.7055]],\n",
      "\n",
      "         [[0.6343, 0.2463, 0.1883],\n",
      "          [0.5139, 0.8274, 0.3923],\n",
      "          [0.6778, 0.4569, 0.6345]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(4, 3, 10, 10)\n",
    "kh, kw = 3, 3\n",
    "weight = torch.rand(5, 3, kh, kw)\n",
    "offset = torch.rand(4, 2 * kh * kw, 8, 8)\n",
    "mask = torch.rand(4, kh * kw, 8, 8)\n",
    "\n",
    "print(weight)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "out = torchvision.ops.deform_conv2d(input, offset, weight, mask=mask)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
